# üì¶ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥–∞–∂ —Å Optuna –∏ LightGBM
import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
import gc
import matplotlib.pyplot as plt
import seaborn as sns
import optuna
from datetime import timedelta
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit


# ================================================
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–∞—á–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# ================================================
def load_data():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–¥–∞–∂–∏ —Å –≤–æ–∑–≤—Ä–∞—Ç–∞–º–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã,
    –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –∏ –∞–∫—Ü–∏–∏, –∞ —Ç–∞–∫–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏.
    """
    print("DEBUG: –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    sales = pd.read_csv('data/sales.csv', parse_dates=['–î–∞—Ç–∞'])
    returns = pd.read_csv('data/returns.csv', parse_dates=['–î–∞—Ç–∞_–≤–æ–∑–≤—Ä–∞—Ç–∞'])
    promotions = pd.read_csv('data/promotions.csv', parse_dates=['–î–∞—Ç–∞_–Ω–∞—á–∞–ª–∞', '–î–∞—Ç–∞_–æ–∫–æ–Ω—á–∞–Ω–∏—è'], dayfirst=True)
    holidays = pd.read_csv('data/holidays.csv', parse_dates=['–î–∞—Ç–∞'])

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –ø–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –ø—Ä–æ–¥–∞–∂–∞–º
    valid_guids = set(sales['GUID_–ø—Ä–æ–¥–∞–∂–∏'])
    returns = returns[returns['GUID_–ø—Ä–æ–¥–∞–∂–∏'].isin(valid_guids)].copy()
    returns_agg = returns.groupby(['GUID_–ø—Ä–æ–¥–∞–∂–∏', 'SKU', '–ú–∞–≥–∞–∑–∏–Ω']).agg(
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ=('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ', 'sum')
    ).reset_index()

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ —Å –≤–æ–∑–≤—Ä–∞—Ç–∞–º–∏ –∏ —Ä–∞—Å—á–µ—Ç –ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏
    sales = pd.merge(sales, returns_agg, on=['GUID_–ø—Ä–æ–¥–∞–∂–∏', 'SKU', '–ú–∞–≥–∞–∑–∏–Ω'], how='left')
    sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ'] = sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ'].fillna(0)
    sales['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'] = sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] - sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ']

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—É–º–º—ã —á–µ–∫–∞ –∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞
    sales['–°—É–º–º–∞_—á–µ–∫–∞'] = sales.groupby('GUID_–ø—Ä–æ–¥–∞–∂–∏')['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'].transform('sum')
    negative_prices = sales[sales['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'] < 0].groupby('GUID_–ø—Ä–æ–¥–∞–∂–∏')['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'].sum()
    sales['–°—É–º–º–∞_—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞'] = sales['GUID_–ø—Ä–æ–¥–∞–∂–∏'].map(negative_prices).fillna(0).abs()

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞—Ö
    sales = pd.merge(sales, holidays[['–î–∞—Ç–∞', '–ù–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–∞–∑–¥–Ω–∏–∫–∞']], on='–î–∞—Ç–∞', how='left')
    sales['–ü—Ä–∞–∑–¥–Ω–∏–∫'] = sales['–ù–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–∞–∑–¥–Ω–∏–∫–∞'].notnull().astype('int8')
    sales.drop(columns=['–ù–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–∞–∑–¥–Ω–∏–∫–∞'], inplace=True)

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∞–∫—Ü–∏—è–º–∏
    sales = pd.merge(sales, promotions, on='–ù–æ–º–µ—Ä_–∞–∫—Ü–∏–∏', how='left')
    sales['–ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞'] = (
        (sales['–ù–æ–º–µ—Ä_–∞–∫—Ü–∏–∏'] != 0) &
        (sales['–î–∞—Ç–∞'] >= sales['–î–∞—Ç–∞_–Ω–∞—á–∞–ª–∞']) &
        (sales['–î–∞—Ç–∞'] <= sales['–î–∞—Ç–∞_–æ–∫–æ–Ω—á–∞–Ω–∏—è'])
    ).astype('int8')
    sales.drop(columns=['–î–∞—Ç–∞_–Ω–∞—á–∞–ª–∞', '–î–∞—Ç–∞_–æ–∫–æ–Ω—á–∞–Ω–∏—è'], inplace=True)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    sales = sales.sort_values(by=['SKU', '–ú–∞–≥–∞–∑–∏–Ω', '–î–∞—Ç–∞'])
    sales = sales.astype({col: 'float32' for col in sales.select_dtypes('float64').columns})
    sales = sales.astype({col: 'int32' for col in sales.select_dtypes('int64').columns if col not in ['–ú–∞–≥–∞–∑–∏–Ω', 'SKU']})
    sales.drop(columns=['GUID_–ø—Ä–æ–¥–∞–∂–∏'], inplace=True, errors='ignore')

    print("DEBUG: –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä DataFrame:", sales.shape)
    return sales

# ================================================
# 2. –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ª–∞–≥–æ–≤—ã—Ö –∏ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö
# ================================================
def create_lags_vectorized(df, lags=[1, 7, 14, 30, 90], target_col='–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'):
    """
    –†–∞—Å—á–µ—Ç –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º groupby.transform –∏ shift.
    """
    group = df.groupby(['SKU', '–ú–∞–≥–∞–∑–∏–Ω'])[target_col]
    for lag in lags:
        df[f'Lag_{lag}'] = group.shift(lag)
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º–µ–¥–∏–∞–Ω–æ–π –ø–æ –≥—Ä—É–ø–ø–µ
        df[f'Lag_{lag}'] = df[f'Lag_{lag}'].fillna(group.transform('median'))
    return df


def create_rolling_vectorized(df, windows=[7, 30, 90], target_col='–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'):
    """
    –†–∞—Å—á–µ—Ç —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º groupby.transform –∏ rolling.
    """
    df.sort_values(by=['SKU', '–ú–∞–≥–∞–∑–∏–Ω', '–î–∞—Ç–∞'], inplace=True)
    group = df.groupby(['SKU', '–ú–∞–≥–∞–∑–∏–Ω'])[target_col]
    for window in windows:
        df[f'MA_{window}'] = group.transform(lambda x: x.rolling(window, min_periods=1).mean())
    return df


def create_features_optimized(df):
    """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏:
        - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        - –õ–∞–≥–æ–≤—ã–µ –∏ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
        - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        - –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        """
    print("DEBUG: –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    df['–î–µ–Ω—å_–Ω–µ–¥–µ–ª–∏'] = df['–î–∞—Ç–∞'].dt.dayofweek.astype('int8')
    df['–ú–µ—Å—è—Ü'] = df['–î–∞—Ç–∞'].dt.month.astype('int8')
    df['–ì–æ–¥'] = df['–î–∞—Ç–∞'].dt.year.astype('int16')
    df['–í—ã—Ö–æ–¥–Ω–æ–π'] = (df['–î–µ–Ω—å_–Ω–µ–¥–µ–ª–∏'] >= 5).astype('int8')
    df['–î–Ω–∏_—Å_–Ω–∞—á–∞–ª–∞'] = (df['–î–∞—Ç–∞'] - df['–î–∞—Ç–∞'].min()).dt.days.astype('int32')
    df['–î–µ–Ω—å_–≥–æ–¥–∞'] = df['–î–∞—Ç–∞'].dt.dayofyear.astype('int16')
    df['Sin_–î–µ–Ω—å'] = np.sin(2 * np.pi * df['–î–µ–Ω—å_–≥–æ–¥–∞'] / 365).astype('float32')
    df['Cos_–î–µ–Ω—å'] = np.cos(2 * np.pi * df['–î–µ–Ω—å_–≥–æ–¥–∞'] / 365).astype('float32')
    print("DEBUG: –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã")

    print("DEBUG: –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    df = create_lags_vectorized(df)
    print("DEBUG: –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã")

    print("DEBUG: –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö")
    df = create_rolling_vectorized(df)
    print("DEBUG: –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ —Å–æ–∑–¥–∞–Ω—ã")

    print("DEBUG: –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ —Ç—Ä—ç–Ω–¥–æ–≤ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ —Ç–æ–≤–∞—Ä—É")
    df['Trend_1_7'] = (df['Lag_1'] - df['MA_7']).astype('float32')
    df['SKU_mean'] = df.groupby('SKU')['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].transform('mean').astype('float32')
    print("DEBUG: –†–∞—Å—á–µ—Ç —Ç—Ä—ç–Ω–¥–æ–≤ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ —Ç–æ–≤–∞—Ä—É –∑–∞–∫–æ–Ω—á–µ–Ω—ã")

    print("DEBUG: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    df['–¶–µ–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'] = (df['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'] - df.groupby('SKU')['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'].transform('mean')).astype('float32')
    df['–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏'] = df['–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏'].fillna(0).astype('float32')
    df['–¢–∏–ø_–∞–∫—Ü–∏–∏'] = df['–¢–∏–ø_–∞–∫—Ü–∏–∏'].fillna('–ù–µ—Ç –∞–∫—Ü–∏–∏')
    print("DEBUG: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")

    print("DEBUG: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª–æ–≥-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫ —Ü–µ–ª–µ–≤–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É")
    df['log_–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'] = np.log1p(df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'])

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    upper_limit = df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].quantile(0.99)
    df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'] = df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].clip(0, upper_limit)

    df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'] = df['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].clip(lower=0)

    gc.collect()
    print("DEBUG: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    return df


# ================================================
# 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å log-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º –∏ Optuna
# ================================================
def train_model_optuna(data, n_trials=50):
    """
        –û–±—É—á–∞–µ—Ç LightGBM-–º–æ–¥–µ–ª—å —Å —Ç—é–Ω–∏–Ω–≥–æ–º Optuna
        """
    print("DEBUG: –°—Ç–∞—Ä—Ç Optuna –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

    target = '–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'
    features = [
        '–î–Ω–∏_—Å_–Ω–∞—á–∞–ª–∞', '–ì–æ–¥', '–î–µ–Ω—å_–Ω–µ–¥–µ–ª–∏', '–ú–µ—Å—è—Ü', '–í—ã—Ö–æ–¥–Ω–æ–π', '–ü—Ä–∞–∑–¥–Ω–∏–∫',
        '–î–µ–Ω—å_–≥–æ–¥–∞', 'Sin_–î–µ–Ω—å', 'Cos_–î–µ–Ω—å',
        'Lag_1', 'Lag_7', 'Lag_14', 'Lag_30', 'Lag_90',
        'MA_7', 'MA_30', 'MA_90', 'Trend_1_7', 'SKU_mean',
        '–ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞', '–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π', '–¶–µ–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ', '–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏',
        '–¢–∏–ø_–∞–∫—Ü–∏–∏', '–ú–∞–≥–∞–∑–∏–Ω', '–°—É–º–º–∞_—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞', '–°—É–º–º–∞_—á–µ–∫–∞']

    categorical_features = ['–ú–∞–≥–∞–∑–∏–Ω', '–¢–∏–ø_–∞–∫—Ü–∏–∏']
    data = data.copy()
    data['–ú–∞–≥–∞–∑–∏–Ω'] = data['–ú–∞–≥–∞–∑–∏–Ω'].astype('category')
    data['–¢–∏–ø_–∞–∫—Ü–∏–∏'] = data['–¢–∏–ø_–∞–∫—Ü–∏–∏'].astype('category')
    data = data.replace([np.inf, -np.inf], np.nan).dropna()

    split_date = data['–î–∞—Ç–∞'].max() - pd.Timedelta(days=30)
    train = data[data['–î–∞—Ç–∞'] < split_date].copy()
    test = data[data['–î–∞—Ç–∞'] >= split_date].copy()

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    def objective(trial):
        params = {
            'objective': 'fair',
            'metric': 'mae',
            'fair_c': trial.suggest_float('fair_c', 0.5, 5.0),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
            'num_leaves': trial.suggest_int('num_leaves', 20, 128),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
            'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),
            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),
            'bagging_freq': 5,
            'verbose': -1,
            'num_threads': 4
        }

        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        tscv = TimeSeriesSplit(n_splits=3)
        maes = []
        for train_idx, val_idx in tscv.split(train):
            train_fold = train.iloc[train_idx]
            val_fold = train.iloc[val_idx]

            print(f"[DEBUG] Fold train shape: {train_fold.shape}, val shape: {val_fold.shape}")
            print(f"[DEBUG] NaNs –≤ train: {train_fold.isna().sum().sum()}, –≤ val: {val_fold.isna().sum().sum()}")

            dtrain = lgb.Dataset(train_fold[features], label=train_fold[target], categorical_feature=categorical_features)
            dval = lgb.Dataset(val_fold[features], label=val_fold[target])
            model = lgb.train(params, dtrain, valid_sets=[dval], num_boost_round=1000,
                              callbacks=[lgb.early_stopping(50, verbose=False)])
            preds = model.predict(val_fold[features])
            maes.append(mean_absolute_error(val_fold[target], preds))

        return np.mean(maes)

    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=n_trials)
    print("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", study.best_params)

    best_params = study.best_params
    best_params.update({'objective': 'fair', 'metric': 'mae', 'verbose': -1, 'num_threads': -1})

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º train
    lgb_train = lgb.Dataset(train[features], label=train[target], categorical_feature=categorical_features)
    lgb_test = lgb.Dataset(test[features], label=test[target])
    model = lgb.train(best_params, lgb_train, num_boost_round=1000,
                      valid_sets=[lgb_test], callbacks=[lgb.early_stopping(50, verbose=False)])
    preds = model.predict(test[features])
    mae = mean_absolute_error(test[target], preds)
    print(f"MAE –Ω–∞ —Ç–µ—Å—Ç–µ: {mae:.4f}")

    return model, study.best_params


# ================================================
# 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
# ================================================
def save_model(model, data, scaler, features, numerical_features, path='sales_model_best.pkl'):
    """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å, scaler, —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –º–∞–ø–ø–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö,
        —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
        """
    print("DEBUG: –ù–∞—á–∞–ª–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
    shop_mapping = dict(enumerate(data['–ú–∞–≥–∞–∑–∏–Ω'].cat.categories))
    promo_mapping = dict(enumerate(data['–¢–∏–ø_–∞–∫—Ü–∏–∏'].cat.categories))
    shop_mapping_reverse = {v: k for k, v in shop_mapping.items()}
    promo_mapping_reverse = {v: k for k, v in promo_mapping.items()}

    joblib.dump({
        'model': model,
        'scaler': scaler,
        'features': features,
        'numerical_features': numerical_features,
        'historical_data': data,
        'shop_mapping': shop_mapping_reverse,
        'promo_mapping': promo_mapping_reverse
    }, path)
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {path}")


# ================================================
# 5. –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
# ================================================
def predict(sku, shop, date, price, promo_active, promo_type, discount_percent, is_holiday, model_path='sales_model_best.pkl'):
    """
        –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ —á–∏—Å—Ç—ã—Ö –ø—Ä–æ–¥–∞–∂ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ SKU, –º–∞–≥–∞–∑–∏–Ω–∞ –∏ –¥–∞—Ç—ã.
        –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ç–æ—á–Ω–æ–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å.
        """
    print("DEBUG: –ù–∞—á–∞–ª–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è SKU:", sku, "Shop:", shop, "Date:", date)
    data = joblib.load(model_path)
    model = data['model']
    scaler = data['scaler']
    features = data['features']
    numerical_features = data['numerical_features']
    historical_data = data['historical_data']
    shop_mapping = data['shop_mapping']
    promo_mapping = data['promo_mapping']

    date = pd.to_datetime(date)
    hist = historical_data[(historical_data['SKU'] == sku) & (historical_data['–ú–∞–≥–∞–∑–∏–Ω'] == shop)]
    hist = hist.sort_values('–î–∞—Ç–∞')

    # –ü–æ–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    exact_record = hist[hist['–î–∞—Ç–∞'] == date]
    if not exact_record.empty:
        value = exact_record['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].iloc[0]
        print(f"–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ: {value}")
        return max(0, round(value))

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    lags = {f'Lag_{l}': hist['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].iloc[-l] if len(hist) >= l else 0 for l in [1, 7, 14, 30, 90]}
    mas = {f'MA_{w}': hist['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].tail(w).mean() if len(hist) >= w else 0 for w in [7, 30, 90]}

    row = pd.DataFrame([{
        '–î–Ω–∏_—Å_–Ω–∞—á–∞–ª–∞': (date - historical_data['–î–∞—Ç–∞'].min()).days,
        '–ì–æ–¥': date.year,
        '–î–µ–Ω—å_–Ω–µ–¥–µ–ª–∏': date.dayofweek,
        '–ú–µ—Å—è—Ü': date.month,
        '–í—ã—Ö–æ–¥–Ω–æ–π': 1 if date.dayofweek >= 5 else 0,
        '–ü—Ä–∞–∑–¥–Ω–∏–∫': is_holiday,
        '–î–µ–Ω—å_–≥–æ–¥–∞': date.dayofyear,
        'Sin_–î–µ–Ω—å': np.sin(2 * np.pi * date.dayofyear / 365),
        'Cos_–î–µ–Ω—å': np.cos(2 * np.pi * date.dayofyear / 365),
        'Trend_1_7': lags.get('Lag_1', 0) - mas.get('MA_7', 0),
        'SKU_mean': hist['–ß–∏—Å—Ç—ã–µ_–ø—Ä–æ–¥–∞–∂–∏'].mean() if not hist.empty else 0,
        **lags,
        **mas,
        '–ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞': promo_active,
        '–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π': price,
        '–¶–µ–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ': price - hist['–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π'].mean() if not hist.empty else 0,
        '–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏': discount_percent,
        '–¢–∏–ø_–∞–∫—Ü–∏–∏': promo_type,
        '–ú–∞–≥–∞–∑–∏–Ω': shop,
        '–°—É–º–º–∞_—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞': 0,
        '–°—É–º–º–∞_—á–µ–∫–∞': price
    }])

    row['–ú–∞–≥–∞–∑–∏–Ω'] = pd.Categorical([shop], categories=list(shop_mapping.keys()))
    row['–¢–∏–ø_–∞–∫—Ü–∏–∏'] = pd.Categorical([promo_type], categories=list(promo_mapping.keys()))
    row[numerical_features] = scaler.transform(row[numerical_features])

    pred = model.predict(row[features])[0]
    pred = max(0, round(pred))
    print(f"–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏: {pred}")
    return pred

# ============================ –ú–∞—Å—Å–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–∑ CSV ============================
def predict_from_csv(input_csv, output_csv='predictions.csv'):
    df = pd.read_csv(input_csv)
    results = []
    for _, row in df.iterrows():
        result = predict(
            sku=row['SKU'],
            shop=row['–ú–∞–≥–∞–∑–∏–Ω'],
            date=row['–î–∞—Ç–∞'],
            price=row['–¶–µ–Ω–∞'],
            promo_active=row.get('–ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞', 0),
            promo_type=row.get('–¢–∏–ø_–∞–∫—Ü–∏–∏', '–ù–µ—Ç –∞–∫—Ü–∏–∏'),
            discount_percent=row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏', 0),
            is_holiday=row.get('–ü—Ä–∞–∑–¥–Ω–∏–∫', 0)
        )
        results.append(result)

    df['–ü—Ä–æ–≥–Ω–æ–∑'] = results
    df.to_csv(output_csv, index=False)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_csv}")
# ============================ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ============================
if __name__ == '__main__':
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    data = load_data()
    data = create_features_optimized(data)
    model, best_params = train_model_optuna(data, n_trials=50)

    features = [
        '–î–Ω–∏_—Å_–Ω–∞—á–∞–ª–∞', '–ì–æ–¥', '–î–µ–Ω—å_–Ω–µ–¥–µ–ª–∏', '–ú–µ—Å—è—Ü', '–í—ã—Ö–æ–¥–Ω–æ–π', '–ü—Ä–∞–∑–¥–Ω–∏–∫',
        '–î–µ–Ω—å_–≥–æ–¥–∞', 'Sin_–î–µ–Ω—å', 'Cos_–î–µ–Ω—å', 'Lag_1', 'Lag_7', 'Lag_14', 'Lag_30', 'Lag_90',
        'MA_7', 'MA_30', 'MA_90', 'Trend_1_7', 'SKU_mean',
        '–ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞', '–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π', '–¶–µ–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ', '–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏',
        '–¢–∏–ø_–∞–∫—Ü–∏–∏', '–ú–∞–≥–∞–∑–∏–Ω', '–°—É–º–º–∞_—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞', '–°—É–º–º–∞_—á–µ–∫–∞']

    numerical_features = ['–î–Ω–∏_—Å_–Ω–∞—á–∞–ª–∞', '–¶–µ–Ω–∞_—Å–æ_—Å–∫–∏–¥–∫–æ–π', '–¶–µ–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ',
                          '–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏', 'MA_7', 'MA_30', 'MA_90', '–î–µ–Ω—å_–≥–æ–¥–∞',
                          'Sin_–î–µ–Ω—å', 'Cos_–î–µ–Ω—å', 'Trend_1_7', 'SKU_mean']

    save_model(model, data, StandardScaler().fit(data[numerical_features]), features, numerical_features)

    ###############################################################################
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∞–π–ª input_cases.csv —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
    # SKU, –ú–∞–≥–∞–∑–∏–Ω, –î–∞—Ç–∞, –¶–µ–Ω–∞, –ê–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–Ω–∞, –¢–∏–ø_–∞–∫—Ü–∏–∏, –ü—Ä–æ—Ü–µ–Ω—Ç_—Å–∫–∏–¥–∫–∏, –ü—Ä–∞–∑–¥–Ω–∏–∫.
    # predict_from_csv('input_cases.csv')
    ###############################################################################

    result = predict(
        sku=373467,
        shop="E14",
        date="2024-12-29",
        price=14.63,
        promo_active=0,
        promo_type="–ù–µ—Ç –∞–∫—Ü–∏–∏",
        discount_percent=0,
        is_holiday=0
    )
    #print(f"–ü—Ä–æ–≥–Ω–æ–∑ —á–∏—Å—Ç—ã—Ö –ø—Ä–æ–¥–∞–∂ –Ω–∞ 2024-11-08 –¥–ª—è E14, SKU 373467: {result}")

    # –§–∞–∫—Ç 5—à—Ç
    result2 = predict(
        sku=369314,
        shop="E14",
        date="2025-04-11",
        price=15.00,
        promo_active=0,
        promo_type="–ù–µ—Ç –∞–∫—Ü–∏–∏",
        discount_percent=0,
        is_holiday=0
    )

    # –§–∞–∫—Ç 4,82 –∫–≥
    result3 = predict(
        sku=356244,
        shop="B90",
        date="2025-04-11",
        price=69.90,
        promo_active=0,
        promo_type="–ù–µ—Ç –∞–∫—Ü–∏–∏",
        discount_percent=0,
        is_holiday=0
    )

    # –§–∞–∫—Ç 3,1–∫–≥
    result4 = predict(
        sku=395419,
        shop="B90",
        date="2025-04-11",
        price=69.90,
        promo_active=0,
        promo_type="–ù–µ—Ç –∞–∫—Ü–∏–∏",
        discount_percent=0,
        is_holiday=0
    )
