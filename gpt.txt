import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
import gc
import optuna
import time
from datetime import timedelta
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit

def clean_column_to_int(series, false_values=('Нет', 'False', 'false', '-', '', None), true_values=('Да', 'True', 'true')):
    ser = series.copy()
    ser = ser.astype(str).str.strip().str.lower()
    ser = ser.replace(list(false_values), 0, regex=False)
    ser = ser.replace(list(true_values), 1, regex=False)
    ser = ser.infer_objects(copy=False)
    ser = pd.to_numeric(ser, errors='coerce').fillna(0).astype('int8')
    return ser

def load_data():
    print("\n=== DEBUG: Начало загрузки данных ===")
    t0 = time.time()
    sales = pd.read_csv('data/sales.csv', parse_dates=['Дата'])
    returns = pd.read_csv('data/returns.csv', parse_dates=['Дата_возврата'])
    promotions = pd.read_csv('data/promotions.csv', parse_dates=['Дата_начала', 'Дата_окончания'], dayfirst=True)
    holidays = pd.read_csv('data/holidays.csv', parse_dates=['Дата'])

    print(f"[{time.time() - t0:.1f}s] Основные файлы загружены.")
    promotions['Это_уценка'] = clean_column_to_int(promotions['Это_уценка'])
    print(f"[{time.time() - t0:.1f}s] 'Это_уценка' очищена.")

    valid_guids = set(sales['GUID_продажи'])
    returns = returns[returns['GUID_продажи'].isin(valid_guids)].copy()
    returns_agg = returns.groupby(['GUID_продажи', 'SKU', 'Магазин']).agg(
        Количество_возвращено=('Количество_возвращено', 'sum')
    ).reset_index()

    sales = pd.merge(sales, returns_agg, on=['GUID_продажи', 'SKU', 'Магазин'], how='left')
    sales['Количество_возвращено'] = sales['Количество_возвращено'].fillna(0)
    sales['Чистые_продажи'] = sales['Количество'] - sales['Количество_возвращено']

    sales['Сумма_чека'] = sales.groupby('GUID_продажи')['Цена_со_скидкой'].transform('sum')
    negative_prices = sales[sales['Цена_со_скидкой'] < 0].groupby('GUID_продажи')['Цена_со_скидкой'].sum()
    sales['Сумма_сертификата'] = sales['GUID_продажи'].map(negative_prices).fillna(0).abs()

    sales = pd.merge(sales, holidays[['Дата', 'Название_праздника', 'Тип_праздника', 'Выходной']], on='Дата', how='left')
    sales['Праздник'] = sales['Название_праздника'].notnull().astype('int8')
    sales['Праздник_тип'] = sales['Тип_праздника'].fillna('Нет')
    sales['Выходной_день'] = sales['Выходной'].fillna(0).astype('int8')
    sales.drop(columns=['Название_праздника', 'Тип_праздника', 'Выходной'], inplace=True)

    sales = pd.merge(sales, promotions, on='Номер_акции', how='left')
    sales['Акция_активна'] = (
        (sales['Номер_акции'] != 0)
        & (sales['Дата'] >= sales['Дата_начала']) 
        & (sales['Дата'] <= sales['Дата_окончания'])
    ).astype('int8')
    sales['Тип_акции'] = sales['Тип_акции'].fillna('Нет акции')
    sales['Процент_скидки'] = sales['Процент_скидки'].fillna(0)
    if sales['Это_уценка'].isna().any():
        print("Пропуски найдены в 'Это_уценка', они будут заполнены 0.")
    sales['Это_уценка'] = sales['Это_уценка'].fillna(0).astype('int8')
    sales['Промо_код_применён'] = sales['Промо_код'].notnull().astype('int8')
    sales.drop(columns=['Дата_начала', 'Дата_окончания', 'Промо_код'], inplace=True)

    sales = sales.sort_values(by=['SKU', 'Магазин', 'Дата'])
    sales = sales.astype({col: 'float32' for col in sales.select_dtypes('float64').columns})
    sales = sales.astype({col: 'int32' for col in sales.select_dtypes('int64').columns if col not in ['Магазин', 'SKU']})
    sales['SKU'] = sales['SKU'].astype(str).astype('category')
    sales.drop(columns=['GUID_продажи'], inplace=True, errors='ignore')

    print(f"=== DEBUG: Данные загружены. Размер DataFrame: {sales.shape} / время: {time.time() - t0:.1f}s ===")
    return sales, holidays, promotions

def add_advanced_features(df, holidays_df, promotions_df):
    print("\n--- DEBUG: Начало расширенного создания признаков ---")
    t0 = time.time()
    df['Скидка_фактическая'] = 1 - (df['Цена_со_скидкой'] / df['Цена_без_скидки'].replace(0, np.nan))
    df['Скидка_фактическая'] = df['Скидка_фактическая'].fillna(0).clip(0, 1)
    df['Была_ли_скидка'] = (df['Цена_со_скидкой'] < df['Цена_без_скидки']).astype('int8')

    promo_typemap = promotions_df.set_index('Номер_акции')['Тип_акции'].to_dict()
    clearance_map = promotions_df.set_index('Номер_акции')['Это_уценка'].to_dict()
    df['Тип_акции_расширенный'] = df['Номер_акции'].map(promo_typemap).fillna('Нет акции')
    df['Является_уценкой'] = df['Номер_акции'].map(clearance_map).fillna(0).astype('int8')

    df = df.sort_values(['SKU', 'Магазин', 'Дата'])
    group = df.groupby(['SKU', 'Магазин'], observed=False)

    for w in [3, 7, 30]:
        print(f"  [add_advanced_features] Rolling: window={w}")
        t1 = time.time()
        df[f'Rolling_sum_{w}'] = group['Чистые_продажи'].transform(lambda x: x.rolling(w, min_periods=1).sum())
        df[f'Rolling_mean_{w}'] = group['Чистые_продажи'].transform(lambda x: x.rolling(w, min_periods=1).mean())
        df[f'Rolling_median_{w}'] = group['Чистые_продажи'].transform(lambda x: x.rolling(w, min_periods=1).median())
        df[f'Rolling_count_{w}'] = group['Чистые_продажи'].transform(lambda x: x.rolling(w, min_periods=1).count())
        print(f"    ...done in {time.time()-t1:.1f}s")

    holidays_set = set(holidays_df['Дата'])
    print("  [add_advanced_features] Считаем признаки близости к праздникам...")
    df['Дней_до_праздника'] = df['Дата'].apply(
        lambda x: min([(h - x).days for h in holidays_set if h >= x] + [999])
    )
    df['Дней_после_праздника'] = df['Дата'].apply(
        lambda x: min([(x - h).days for h in holidays_set if h <= x] + [999])
    )

    print("  [add_advanced_features] Считаем уникальные акции за 30 дней (ускоренный способ)...")
    # Быстрая векторизованная версия подсчета уникальных акций за 30 дней для каждой группы
    # Работает через преобразование в одномерный массив с индексами дат
    df['Акций_за_30д'] = 0
    for (sku, store), sub_df in group:
        idx = sub_df.index
        akc = sub_df['Номер_акции'].values
        dates = sub_df['Дата'].values
        result = np.zeros(len(sub_df), dtype=np.int16)
        last_seen = {}
        for i in range(len(sub_df)):
            win_start = dates[i] - np.timedelta64(29, 'D')
            uniq = set()
            for j in range(i, -1, -1):
                if dates[j] < win_start:
                    break
                uniq.add(akc[j])
            result[i] = len(uniq)
        df.loc[idx, 'Акций_за_30д'] = result
    print(f"    ...done in {time.time()-t0:.1f}s")

    df['Весовой'] = df['Весовой'].astype('int8')
    if 'Карта_клиента' in df.columns:
        df['Карта_клиента'] = df['Карта_клиента'].astype('int8')
    else:
        df['Карта_клиента'] = 0

    print(f"--- DEBUG: Завершено расширенное создание признаков за {time.time()-t0:.1f}s ---")
    return df

def create_lags_vectorized(df, lags=[1, 7, 14, 30, 90], target_col='Чистые_продажи'):
    t0 = time.time()
    group = df.groupby(['SKU', 'Магазин'], observed=False)[target_col]
    for lag in lags:
        print(f"  [create_lags_vectorized] Lag {lag}")
        df[f'Lag_{lag}'] = group.shift(lag)
        df[f'Lag_{lag}'] = df[f'Lag_{lag}'].fillna(group.transform('median'))
    print(f"  [create_lags_vectorized] Все лаги рассчитаны за {time.time()-t0:.1f}s")
    return df

def create_rolling_vectorized(df, windows=[7, 30, 90], target_col='Чистые_продажи'):
    t0 = time.time()
    df.sort_values(by=['SKU', 'Магазин', 'Дата'], inplace=True)
    group = df.groupby(['SKU', 'Магазин'], observed=False)[target_col]
    for window in windows:
        print(f"  [create_rolling_vectorized] Скользящее среднее {window}")
        df[f'MA_{window}'] = group.transform(lambda x: x.rolling(window, min_periods=1).mean())
    print(f"  [create_rolling_vectorized] Все скользящие средние рассчитаны за {time.time()-t0:.1f}s")
    return df

def create_features_optimized(df, holidays_df, promotions_df):
    print("\n=== DEBUG: Начало создания временных признаков ===")
    t0 = time.time()
    df['День_недели'] = df['Дата'].dt.dayofweek.astype('int8')
    df['Месяц'] = df['Дата'].dt.month.astype('int8')
    df['Год'] = df['Дата'].dt.year.astype('int16')
    df['Выходной'] = (df['День_недели'] >= 5).astype('int8')
    df['Дни_с_начала'] = (df['Дата'] - df['Дата'].min()).dt.days.astype('int32')
    df['День_года'] = df['Дата'].dt.dayofyear.astype('int16')
    df['Sin_День'] = np.sin(2 * np.pi * df['День_года'] / 365).astype('float32')
    df['Cos_День'] = np.cos(2 * np.pi * df['День_года'] / 365).astype('float32')
    print(f"  [create_features_optimized] Временные признаки созданы за {time.time()-t0:.1f}s")

    print("=== DEBUG: Начало расчета лаговых признаков ===")
    df = create_lags_vectorized(df)
    print("=== DEBUG: Лаговые признаки созданы ===")

    print("=== DEBUG: Начало расчета скользящих средних ===")
    df = create_rolling_vectorized(df)
    print("=== DEBUG: Скользящие средние созданы ===")

    print("=== DEBUG: Начало расширенного feature engineering ===")
    df = add_advanced_features(df, holidays_df, promotions_df)

    print("=== DEBUG: Начало расчета трэндов и среднего по товару ===")
    df['Trend_1_7'] = (df['Lag_1'] - df['MA_7']).astype('float32')
    df['SKU_mean'] = df.groupby('SKU')['Чистые_продажи'].transform('mean').astype('float32')
    print("=== DEBUG: Расчет трэндов и среднего по товару закончены ===")

    print("=== DEBUG: Дополнительные признаки добавлены ===")
    df['Цена_отклонение'] = (df['Цена_со_скидкой'] - df.groupby('SKU')['Цена_со_скидкой'].transform('mean')).astype('float32')

    print("=== DEBUG: Применение лог-преобразования к целевому признаку ===")
    df['log_Чистые_продажи'] = np.log1p(df['Чистые_продажи'])

    upper_limit = df['Чистые_продажи'].quantile(0.99)
    df['Чистые_продажи'] = df['Чистые_продажи'].clip(0, upper_limit)
    df['Чистые_продажи'] = df['Чистые_продажи'].clip(lower=0)

    gc.collect()
    print(f"=== DEBUG: Создание признаков завершено за {time.time()-t0:.1f}s ===")
    return df

# ================================================
# 4. Расширенный список признаков и категориальных для модели
# ================================================
features = [
    # Временные и базовые
    'Дни_с_начала', 'Год', 'День_недели', 'Месяц', 'Выходной', 'Праздник',
    'Праздник_тип', 'Выходной_день', 'День_года', 'Sin_День', 'Cos_День',
    # Лаги и скользящие средние
    'Lag_1', 'Lag_7', 'Lag_14', 'Lag_30', 'Lag_90',
    'MA_7', 'MA_30', 'MA_90', 'Trend_1_7', 'SKU_mean',
    # Цены и скидки
    'Цена_со_скидкой', 'Цена_отклонение', 'Процент_скидки', 'Сумма_сертификата', 'Сумма_чека',
    'Скидка_фактическая', 'Была_ли_скидка',
    # Акции и промо
    'Акция_активна', 'Тип_акции', 'Тип_акции_расширенный', 'Является_уценкой', 'Промо_код_применён',
    # Агрегации по продажам
    'Rolling_sum_3', 'Rolling_mean_3', 'Rolling_median_3', 'Rolling_count_3',
    'Rolling_sum_7', 'Rolling_mean_7', 'Rolling_median_7', 'Rolling_count_7',
    'Rolling_sum_30', 'Rolling_mean_30', 'Rolling_median_30', 'Rolling_count_30',
    'Акций_за_30д',
    # Праздничные фичи
    'Дней_до_праздника', 'Дней_после_праздника',
    # Прочие
    'Магазин', 'SKU', 'Весовой', 'Карта_клиента'
]

categorical_features = [
    'Магазин',
    'Тип_акции',
    'Тип_акции_расширенный',
    'Праздник_тип',
    'Является_уценкой',
    'Промо_код_применён',
    'Весовой',
    'Карта_клиента',
    'SKU'  # SKU теперь как категория!
]

# ================================================
# 5. Обработка категориальных признаков перед обучением
# ================================================
def prepare_categoricals(data, categorical_features):
    for col in categorical_features:
        if col in data.columns:
            data[col] = data[col].astype('category')
    return data

# ================================================
# 6. Обучение модели
# ================================================
def train_model_optuna(data, features, categorical_features, n_trials=50, random_state=42):
    """
    Обучение модели LightGBM с подбором гиперпараметров через Optuna.
    """

    import optuna

    target = 'Чистые_продажи'
    data = data.replace([np.inf, -np.inf], np.nan).dropna(subset=features + [target])

    # Разделение train/test по времени (последние 30 дней — тест)
    split_date = data['Дата'].max() - pd.Timedelta(days=30)
    train = data[data['Дата'] < split_date].copy()
    test = data[data['Дата'] >= split_date].copy()

    def objective(trial):
        params = {
            'objective': 'regression',
            'metric': 'mae',
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
            'num_leaves': trial.suggest_int('num_leaves', 20, 128),
            'max_depth': trial.suggest_int('max_depth', 4, 15),
            'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),
            'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),
            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': random_state,
            'n_jobs': 31
        }
        tscv = TimeSeriesSplit(n_splits=3)
        maes = []
        X = train[features]
        y = train[target]
        for train_idx, val_idx in tscv.split(X):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            dtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)
            dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)
            model = lgb.train(
                params, dtrain,
                valid_sets=[dval],
                num_boost_round=1000,
                early_stopping_rounds=50,
                verbose_eval=False
            )
            preds = model.predict(X_val, num_iteration=model.best_iteration)
            maes.append(mean_absolute_error(y_val, preds))
        return np.mean(maes)

    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=n_trials)
    print("Лучшие параметры:", study.best_params)

    best_params = study.best_params
    best_params.update({
        'objective': 'regression',
        'metric': 'mae',
        'verbose': -1,
        'random_state': random_state,
        'n_jobs': 31
    })

    # Финальное обучение на train
    lgb_train = lgb.Dataset(train[features], label=train[target], categorical_feature=categorical_features)
    lgb_test = lgb.Dataset(test[features], label=test[target])
    model = lgb.train(
        best_params,
        lgb_train,
        num_boost_round=1000,
        valid_sets=[lgb_test],
        early_stopping_rounds=50,
        verbose_eval=50
    )
    preds = model.predict(test[features], num_iteration=model.best_iteration)
    mae = mean_absolute_error(test[target], preds)
    print(f"MAE на тесте: {mae:.4f}")

    return model, best_params, mae, test, preds

# ================================================
# 7. Сохранение модели
# ================================================
def save_model(model, data, features, categorical_features, model_path='sales_lgbm_model.pkl'):
    """
    Сохраняет LightGBM модель и метаинформацию для последующего использования.
    """
    # Категориальные маппинги (для восстановления при инференсе)
    category_maps = {
        col: dict(enumerate(data[col].cat.categories))
        for col in categorical_features if col in data.columns and hasattr(data[col], 'cat')
    }
    joblib.dump({
        'model': model,
        'features': features,
        'categorical_features': categorical_features,
        'category_maps': category_maps
    }, model_path)
    print(f"Модель и признаки сохранены в файл: {model_path}")

def prepare_categoricals_for_inference(df, category_maps, categorical_features):
    """
    Приводит категориальные признаки к тем же категориям, что были при обучении.
    """
    for col in categorical_features:
        if col in df.columns and col in category_maps:
            # Приводим к категориям с тем же порядком
            df[col] = pd.Categorical(df[col], categories=list(category_maps[col].values()))
    return df

def predict_from_dataframe(df, model_path='sales_lgbm_model.pkl'):
    """
    Делает предсказание для датафрейма df с признаками, аналогичными обучению.
    Возвращает массив предсказаний.
    """
    # Загрузка модели и метаинформации
    model_data = joblib.load(model_path)
    model = model_data['model']
    features = model_data['features']
    categorical_features = model_data['categorical_features']
    category_maps = model_data['category_maps']

    # Подготовка категориальных признаков
    df = prepare_categoricals_for_inference(df, category_maps, categorical_features)
    # Заполняем возможные пропуски в нужных признаках
    for col in features:
        if col not in df.columns:
            df[col] = 0
    # Порядок признаков
    df = df[features]

    preds = model.predict(df, num_iteration=getattr(model, 'best_iteration', None))
    # Если предсказываем продажи — всегда >= 0
    preds = np.clip(preds, 0, None)
    return preds

def predict_from_csv(input_csv, output_csv='predictions.csv', model_path='sales_lgbm_model.pkl'):
    """
    Массовое предсказание: читает данные из CSV (с нужными признаками), делает предсказания, сохраняет результат.
    """
    df = pd.read_csv(input_csv)
    preds = predict_from_dataframe(df, model_path=model_path)
    df['Прогноз'] = preds
    df.to_csv(output_csv, index=False)
    print(f"Результаты сохранены в {output_csv}")

def predict_single_case(feature_dict, model_path='sales_lgbm_model.pkl'):
    """
    Предсказание для одного случая: подайте dict признаков как на обучении.
    """
    df = pd.DataFrame([feature_dict])
    preds = predict_from_dataframe(df, model_path=model_path)
    return preds[0]

def auto_generate_features(raw_cases, model_path='sales_lgbm_model.pkl', min_date='2020-01-01'):
    """
    Автоматически достраивает недостающие признаки для предсказания продаж.
    """
    # Загрузка meta-информации модели
    model_data = joblib.load(model_path)
    features = model_data['features']
    categorical_features = model_data['categorical_features']
    category_maps = model_data['category_maps']

    # Создание DataFrame из минимального ввода
    df = pd.DataFrame(raw_cases)
    if 'Дата' in df.columns:
        df['Дата'] = pd.to_datetime(df['Дата'])

    # Автоматически рассчитываем временные признаки
    if 'День_недели' in features:
        df['День_недели'] = df['Дата'].dt.dayofweek
    if 'Месяц' in features:
        df['Месяц'] = df['Дата'].dt.month
    if 'Год' in features:
        df['Год'] = df['Дата'].dt.year
    if 'День_года' in features:
        df['День_года'] = df['Дата'].dt.dayofyear
    if 'Sin_День' in features:
        df['Sin_День'] = np.sin(2 * np.pi * df['Дата'].dt.dayofyear / 365)
    if 'Cos_День' in features:
        df['Cos_День'] = np.cos(2 * np.pi * df['Дата'].dt.dayofyear / 365)
    if 'Дни_с_начала' in features:
        min_dt = pd.to_datetime(min_date)
        df['Дни_с_начала'] = (df['Дата'] - min_dt).dt.days

    # Бинарные и категориальные, если не заданы
    if 'Праздник' in features and 'Праздник' not in df.columns:
        df['Праздник'] = 0
    if 'Выходной' in features and 'Выходной' not in df.columns:
        df['Выходной'] = (df['День_недели'] >= 5).astype(int)
    if 'Выходной_день' in features and 'Выходной_день' not in df.columns:
        df['Выходной_день'] = df['Выходной']

    if 'Тип_акции' in features and 'Тип_акции' not in df.columns:
        df['Тип_акции'] = "Нет акции"
    if 'Тип_акции_расширенный' in features and 'Тип_акции_расширенный' not in df.columns:
        df['Тип_акции_расширенный'] = "Нет акции"
    if 'Праздник_тип' in features and 'Праздник_тип' not in df.columns:
        df['Праздник_тип'] = "Нет"

    # Другие признаки по умолчанию
    for f in features:
        if f not in df.columns:
            df[f] = 0

    # SKU и Магазин как строка-категория
    if 'SKU' in df.columns:
        df['SKU'] = df['SKU'].astype(str)
    if 'Магазин' in df.columns:
        df['Магазин'] = df['Магазин'].astype(str)

    # Категориальные признаки — к нужным категориям
    for col in categorical_features:
        if col in df.columns and col in category_maps:
            df[col] = pd.Categorical(df[col], categories=list(category_maps[col].values()))

    df = df[features]
    return df

# ================================================
# 6. Пример основного пайплайна
# ================================================
if __name__ == '__main__':
    print("Загрузка и обработка данных...")
    data, holidays, promotions = load_data()
    data = create_features_optimized(data, holidays, promotions)
    data = prepare_categoricals(data, categorical_features)

    model, best_params, mae, test, preds = train_model_optuna(
        data, features, categorical_features, n_trials=1
    )

    save_model(model, data, features, categorical_features, 'sales_lgbm_gpt_model.pkl')

    ###############################################################################
    # Подготовить файл input_cases.csv с колонками:
    # SKU, Магазин, Дата, Цена, Акция_активна, Тип_акции, Процент_скидки, Праздник.
    # predict_from_csv('input_cases.csv')
    ###############################################################################

    cases = [
        {
            "SKU": 373467,
            "Магазин": "E14",
            "Дата": "2024-12-29",
            "Цена_со_скидкой": 14.63,
        },
        {
            # Факт 5шт
            "SKU": 369314,
            "Магазин": "E14",
            "Дата": "2025-04-11",
            "Цена_со_скидкой": 15.00,
        },
        {
            # Факт 4,82 кг
            "SKU": 356244,
            "Магазин": "B90",
            "Дата": "2025-04-11",
            "Цена_со_скидкой": 69.90,
        },
        {
            # Факт 3,1кг
            "SKU": 395419,
            "Магазин": "B90",
            "Дата": "2025-04-11",
            "Цена_со_скидкой": 69.90,
        }
    ]
    # Автогенерация фичей
    df_ready = auto_generate_features(cases, model_path="sales_lgbm_model.pkl", min_date="2020-01-01")
    predictions = predict_from_dataframe(df_ready, model_path="sales_lgbm_model.pkl")
    for i, pred in enumerate(predictions):
        print(f"SKU={cases[i]['SKU']} Магазин={cases[i]['Магазин']} Дата={cases[i]['Дата']} -> Прогноз={pred:.2f}")

    
